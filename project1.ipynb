{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_train, x_train, _ = load_csv_data('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanitizing the missing values and standardize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JULES FLO: si on sanitize apr√®s il y avait des nan jsp pourquoi, amdahl\n",
    "x_train_san = sanitize(x_train)\n",
    "y_train = y_train.reshape((y_train.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_22_train = x_train_san[:, 22]\n",
    "categories_22 = np.unique(feature_22_train)\n",
    "x_train_san_minus_22 = x_train_san[:, np.array(range(x.shape[1])) != 22]\n",
    "x_train_sep = []\n",
    "y_train_sep = []\n",
    "\n",
    "for i in categories_22: # Assuming same set of category in the training and testing\n",
    "    x_train_sep.append(x_train_san_minus_22[feature_22_train == i, :])\n",
    "    y_train_sep.append(y_train[feature_22_train == i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-0c184010f8fd>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-0c184010f8fd>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    predictions[ind] =\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Rebuilding final y for submission, in progress\n",
    "N = x_test.shape[0]\n",
    "predictions = np.zeros(N)\n",
    "for i in categories_22:\n",
    "    ind = np.arange(N)[np.isclose(i, features_22_test, atol=1e-04)]\n",
    "    predictions[ind] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0 with loss 6.450879851498423 and gradient norm: 5.2949655558829996\n",
      "Iteration : 250 with loss 0.33888191557092795 and gradient norm: 0.23865532916917823\n",
      "Iteration : 500 with loss 0.28938969362720307 and gradient norm: 0.06947344049309992\n",
      "Iteration : 750 with loss 0.28333925216863215 and gradient norm: 0.03555978862893712\n",
      "Iteration : 0 with loss 7.452108683713229 and gradient norm: 5.818346417752108\n",
      "Iteration : 250 with loss 0.44345963076205164 and gradient norm: 0.21575812346784867\n",
      "Iteration : 500 with loss 0.4012819407366933 and gradient norm: 0.0727687613696616\n",
      "Iteration : 750 with loss 0.3930971455255257 and gradient norm: 0.046254790474539606\n",
      "Iteration : 0 with loss 13.67910152265491 and gradient norm: 12.796020211909392\n",
      "Iteration : 250 with loss 0.5159878990640682 and gradient norm: 0.3421576311697902\n",
      "Iteration : 500 with loss 0.391543583051741 and gradient norm: 0.1334200865209421\n",
      "Iteration : 750 with loss 0.3675070379449254 and gradient norm: 0.06923134444376204\n",
      "Iteration : 0 with loss 47.063741454514876 and gradient norm: 42.507412281174965\n",
      "Iteration : 250 with loss 0.4279531192977199 and gradient norm: 0.2415670237034154\n",
      "Iteration : 500 with loss 0.3737766858484782 and gradient norm: 0.07978364641943766\n",
      "Iteration : 750 with loss 0.3660322870330254 and gradient norm: 0.03599448926534579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8136979171879535,\n",
       " 0.7054317548746518,\n",
       " 0.7315746640465273,\n",
       " 0.7268092402093485]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = []\n",
    "weights = []\n",
    "for i, x_chunk in enumerate(x_train_sep):\n",
    "    w_init = np.random.rand(x_chunk.shape[1], 1)\n",
    "    w, loss = least_squares_GD(y_train_sep[i], x_chunk, w_init, 1000, 0.01, verbose=True) \n",
    "    y_pred = predict_labels(w, x_chunk)\n",
    "    accuracies.append(compute_accuracy_linear_reg(y_train_sep[i], y_pred))\n",
    "    weights.append(w)\n",
    "    \n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old but kept because can be useful as basis\n",
    "N = sanitized_x.shape[0]\n",
    "inds = np.random.choice(range(N), 100000, replace=False)\n",
    "sanitized_x_sub = sanitized_x[inds, :]\n",
    "sanitized_x_sub = sanitized_x_sub[:, [0,1,2,3,7,8,9,10,11,13,14,17,19,21,22,29]]\n",
    "sanitized_y_sub = sanitized_y[inds]\n",
    "x_train, x_test, y_train, y_test = split_data(sanitized_x, sanitized_y, 0.8)\n",
    "number_of_w = 1\n",
    "\n",
    "for degree in range(1, 5)\n",
    "    tx_train = build_poly(x_train, degree)\n",
    "    tx_test = build_poly(x_test, degree)\n",
    "    for gamma in np.array([0.01, 0.05, 0.1, 0.5]):\n",
    "        print(\"Running logistic regression with polynomial feature expansion with degree\", degree, \n",
    "                 \"and gamma\", gamma,\", with\", number_of_w, \"different initial weights.\")\n",
    "        for i in  range(number_of_w):\n",
    "            w_init = np.random.rand(tx_train.shape[1], 1)\n",
    "            w, loss = logistic_regression(y_train, tx_train, w_init, 1000, gamma, verbose=True)\n",
    "            print(i,\":\")\n",
    "            print(\"Accuracy on training set\", compute_accuracy(y_train, tx_train, w))\n",
    "            print(\"Accuracy on test set:, \", compute_accuracy(y_test, tx_test, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_, x_test, ids_test = load_csv_data('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_san  = sanitize(x_test)\n",
    "\n",
    "feature_22_test = x_test_san[:, 22]\n",
    "x_test_san_minus_22 = x_test_san[:, np.array(range(x.shape[1])) != 22]\n",
    "x_test_sep = []\n",
    "\n",
    "for i in categories_22:\n",
    "    x_test_sep.append(x_test_san_minus_22[feature_22_test == i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(weights, x_test)\n",
    "# Rebuild original form for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'predictions.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
